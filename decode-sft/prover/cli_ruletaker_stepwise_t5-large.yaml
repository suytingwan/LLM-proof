seed_everything: 1
trainer:
  gpus: 1
  gradient_clip_val: 0.5
  max_epochs: 20
  accumulate_grad_batches: 21
  log_every_n_steps: 5
  check_val_every_n_epoch: 1
  #limit_val_batches: 200
  num_sanity_val_steps: 0
  default_root_dir: ./eval_ruletaker
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args: 
        logging_interval: step
model:
  stepwise: true
  max_num_steps: 30
  lr: 1e-4
  warmup_steps: 1000
  model_name: t5-large
  num_beams: 10
  topk: 10
  verifier_ckpt: null
  verifier_weight: 0.0
  proof_search: false
  oracle_prover: false
  oracle_verifier: false
data:
  dataset: ruletaker
  sample_goal: intermediates # hypothesis | intermediates
  subtree_proved_prob: 1.0
  subtree_proved_all_or_none: false
  batch_size: 10
  num_workers: 2
  max_input_len: 512
  max_output_len: 64
  path_train: /home/ysuay/codes/LLM+Reason/codes/NLProofS/data/proofwriter-dataset-V2020.12.3/preprocessed_OWA/depth-3ext/meta-train.jsonl 
  path_val: /home/ysuay/codes/LLM+Reason/codes/NLProofS/data/proofwriter-dataset-V2020.12.3/preprocessed_OWA/depth-3ext/meta-train.jsonl
  path_test: /home/ysuay/codes/LLM+Reason/codes/NLProofS/data/proofwriter-dataset-V2020.12.3/preprocessed_OWA/depth-3ext/meta-test.jsonl
