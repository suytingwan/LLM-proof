seed_everything: 1
trainer:
  gpus: 1
  gradient_clip_val: 0.5
  max_epochs: 500
  accumulate_grad_batches: 16
  log_every_n_steps: 5
  check_val_every_n_epoch: 10
  num_sanity_val_steps: 0
  default_root_dir: /home/ysuay/codes/LLM+Reason/codes/LLMProofs/decode_sft/prover/eval_entailmentbank_task1
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args: 
        logging_interval: step
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        every_n_epochs: 20
        save_on_train_epoch_end: true

model:
  stepwise: true
  max_num_steps: 20
  lr: 0.0001
  warmup_steps: 1000
  model_name: t5-large
  num_beams: 10
  topk: 10
  verifier_ckpt: null
  verifier_weight: 0.0
  proof_search: false
  oracle_prover: false
  oracle_verifier: false
data:
  dataset: entailmentbank
  sample_goal: hypothesis # hypothesis | intermediates
  subtree_proved_prob: 0.5
  subtree_proved_all_or_none: true
  batch_size: 4
  num_workers: 2
  max_input_len: 1024
  max_output_len: 64
  path_train: /home/ysuay/codes/LLM+Reason/codes/NLProofS/data/entailment_trees_emnlp2021_data_v3/dataset/task_1/train.jsonl
  path_val: /home/ysuay/codes/LLM+Reason/codes/NLProofS/data/entailment_trees_emnlp2021_data_v3/dataset/task_1/dev.jsonl
  path_test: /home/ysuay/codes/LLM+Reason/codes/NLProofS/data/entailment_trees_emnlp2021_data_v3/dataset/task_1/test.jsonl
